var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = Llama2Inference","category":"page"},{"location":"#Llama2Inference","page":"Home","title":"Llama2Inference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for Llama2Inference.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [Llama2Inference]","category":"page"},{"location":"#Llama2Inference.forward-Tuple{Transformer, RunState, Int64, Int64}","page":"Home","title":"Llama2Inference.forward","text":"forward(transformer::Transformer, state::RunState, token::Int, pos::Int)\n\nForward the token at position pos through the transformer model.\n\nThe foward pass corresponds to the LlaMa2 decoder architecture and is based on the C implementation by Andrej Karpathy.\n\nArguments\n\ntransformer::Transformer: The transformer object containg config, weights and the token embedding table.\nstate::RunState: The state object to store the intermediate results during the forward pass.\ntoken::Int: The token to forward through the transformer.\npos::Int: The position of the token in the sequence. The position is 1-based, which means the first position in a sequence is 1.\n\nExample\n\njulia> config, weights = read_checkpoint(\"./stories15M.bin\")\njulia> transformer = Transformer(config, weights)\njulia> tokenizer = build_tokenizer(\"./tokenizer.bin\", Int(config.vocab_size))\njulia> state = RunState(config)\njulia> token = 2\njulia> pos = 1\njulia> forward(transformer, state, token, pos)\n32000-element Vector{Float32}:\n -6.790799\n  0.828116\n -6.790441\n -6.7904925\n -6.7904897\n -6.7906227\n  â‹®\n -6.7905755\n -6.7905526\n -6.7907033\n -6.790716\n -6.7906933\n -6.790564\n\n\n\n\n\n","category":"method"},{"location":"#Llama2Inference.generate-Tuple{Transformer, Tokenizer, Sampler, Int64}","page":"Home","title":"Llama2Inference.generate","text":"generate(transformer::Transformer, tokenizer::Tokenizer, sampler::Sampler, steps::Int; prompt::String=\"\")\n\nGenerate a sequence of tokens using the transformer.\n\nArguments\n\ntransformer::Transformer: The transformer object containg config and weights.\ntokenizer::Tokenizer: The tokenizer object to encode and decode tokens.\nsampler::Sampler: The sampler object to sample a token from the output logits.\nsteps::Int: The number of maximum tokens to generate.\nprompt::String: The input text to start the generation. If none, the generation starts with an empty string.\n\nExample\n\njulia> config, weights = read_checkpoint(\"./stories15M.bin\")\njulia> transformer = Transformer(config, weights)\njulia> tokenizer = build_tokenizer(\"./tokenizer.bin\", Int(config.vocab_size))\njulia> sampler = Sampler(config.vocab_size, 0.0f0, 0.9f0)\njulia> generate(transformer, tokenizer, sampler, 23; prompt=\"The universe\")\nThe universe was bright and full of stars. Every night, the stars would twinkle and shine.\n\n\n\n\n\n","category":"method"},{"location":"#Llama2Inference.rmsnorm!-Tuple{AbstractVector{Float32}, AbstractVector{Float32}, AbstractVector{Float32}}","page":"Home","title":"Llama2Inference.rmsnorm!","text":"rmsnorm!(out::AbstractArray{Float32, 1}, x::AbstractArray{Float32,1}, weight::AbstractArray{Float32,1})\n\nNormalize out in place by the root mean square of x and multiply with weight.\n\nout_i = fracx_iRMS(x) * weight_i where RMS(x) = sqrt\frac1n * sum_i=1^n x_i^2 + 1e-5\n\n1e-5 is added for numerical stability in the square root part.\n\n\n\n\n\n","category":"method"},{"location":"#Llama2Inference.sample_topp-Tuple{Sampler, Vector{Float32}, Float32}","page":"Home","title":"Llama2Inference.sample_topp","text":"sample_topp(sampler::Sampler, logits::Vector{Float32}, coin::Float32)::Int\n\ntop-p sampling (or \"nucleus sampling\") samples from the smallest set of tokens that exceed probability topp.\n\n\n\n\n\n","category":"method"},{"location":"#Llama2Inference.softmax!-Tuple{AbstractVector{Float32}}","page":"Home","title":"Llama2Inference.softmax!","text":"softmax!(x::AbstractArray{Float32,1})\n\nSoftmax the values in x in place.\n\nx_i = frace^x_isum_j=1^n e^x_j\n\n\n\n\n\n","category":"method"}]
}
