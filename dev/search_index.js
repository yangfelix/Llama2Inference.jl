var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = Llama2Inference","category":"page"},{"location":"#Llama2Inference","page":"Home","title":"Llama2Inference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for Llama2Inference.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [Llama2Inference]","category":"page"},{"location":"#Llama2Inference.forward-Tuple{Transformer, RunState, Int64, Int64}","page":"Home","title":"Llama2Inference.forward","text":"forward(transformer::Transformer, state::RunState, token::Int, pos::Int)\n\nForward pass of the transformer model with the input token at position pos.\n\nLlaMa2 was used as the architecure of the transformer model and it's modifications. The forward pass looks like the following:\n\nforward through all layers\n\na) RMSNorm\nb) linear project x into Query, Key, Value with Wq, Wk, Wv\nc) RoPE relative positional encoding\nd) multihead attention\ne) residual of x + RMSNorm\nf) MLP with SwiGLU non-linearity\n\nrmsnrom\nclassify into logits\n\n\n\n\n\n","category":"method"},{"location":"#Llama2Inference.rmsnorm!-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"Home","title":"Llama2Inference.rmsnorm!","text":"rmsnorm!(out::Array{T, 1}, x::Array{T,1}, weight::Array{T,1}) where T<:AbstractFloat\n\nnormalize out in place by the root mean square of x and multiply by the learned weights weight.\n\n\n\n\n\n","category":"method"},{"location":"#Llama2Inference.sample_topp-Tuple{Sampler, Vector{Float32}, Float32}","page":"Home","title":"Llama2Inference.sample_topp","text":"sample_topp(sampler::Sampler, logits::Vector{Float32}, coin::Float32)::Int\n\ntop-p sampling (or \"nucleus sampling\") samples from the smallest set of tokens that exceed probability topp.\n\n\n\n\n\n","category":"method"},{"location":"#Llama2Inference.softmax!-Union{Tuple{AbstractVector{T2}}, Tuple{T2}} where T2<:AbstractFloat","page":"Home","title":"Llama2Inference.softmax!","text":"softmax!(x::T{T2,1}) where {T<:AbstractArray, T2<:AbstractFloat}\n\nsoftmax the values in x in place, up to position pos inclusively.\n\n\n\n\n\n","category":"method"}]
}
