var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = Llama2Inference","category":"page"},{"location":"#Llama2Inference","page":"Home","title":"Llama2Inference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for Llama2Inference.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [Llama2Inference]","category":"page"},{"location":"#Llama2Inference.forward-Tuple{Transformer, RunState, Int64, Int64}","page":"Home","title":"Llama2Inference.forward","text":"forward(transformer::Transformer, state::RunState, token::Int, pos::Int)\n\nForward pass of the transformer model with the input token at position pos.\n\nLlaMa2 was used as the architecure of the transformer model and it's modifications. The forward pass looks like the following:\n\nforward through all layers\n\na) RMSNorm\nb) linear project x into Query, Key, Value with Wq, Wk, Wv\nc) RoPE relative positional encoding\nd) multihead attention\ne) residual of x + RMSNorm\nf) MLP with SwiGLU non-linearity\n\nrmsnrom\nclassify into logits\n\n\n\n\n\n","category":"method"},{"location":"#Llama2Inference.rmsnorm!-Tuple{AbstractVector{Float32}, AbstractVector{Float32}, AbstractVector{Float32}}","page":"Home","title":"Llama2Inference.rmsnorm!","text":"rmsnorm!(out::AbstractArray{Float32, 1}, x::AbstractArray{Float32,1}, weight::AbstractArray{Float32,1})\n\nNormalize out in place by the root mean square of x and multiply with weight. 1e-5 is added for numerical stability in the square root part.\n\nout_i = \fracx_iRMS(x) * weight_i where RMS(x) = sqrt\frac1n * sum_i=1^n x_i^2 + 1e-5\n\n\n\n\n\n","category":"method"},{"location":"#Llama2Inference.sample_topp-Tuple{Sampler, Vector{Float32}, Float32}","page":"Home","title":"Llama2Inference.sample_topp","text":"sample_topp(sampler::Sampler, logits::Vector{Float32}, coin::Float32)::Int\n\ntop-p sampling (or \"nucleus sampling\") samples from the smallest set of tokens that exceed probability topp.\n\n\n\n\n\n","category":"method"},{"location":"#Llama2Inference.softmax!-Tuple{AbstractVector{Float32}}","page":"Home","title":"Llama2Inference.softmax!","text":"softmax!(x::AbstractArray{Float32,1})\n\nSoftmax the values in x in place.\n\nx_i = \frace^x_isum_j=1^n e^x_j\n\n\n\n\n\n","category":"method"}]
}
