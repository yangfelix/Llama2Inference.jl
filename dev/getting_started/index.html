<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting Started · Llama2Inference.jl</title><meta name="title" content="Getting Started · Llama2Inference.jl"/><meta property="og:title" content="Getting Started · Llama2Inference.jl"/><meta property="twitter:title" content="Getting Started · Llama2Inference.jl"/><meta name="description" content="Documentation for Llama2Inference.jl."/><meta property="og:description" content="Documentation for Llama2Inference.jl."/><meta property="twitter:description" content="Documentation for Llama2Inference.jl."/><meta property="og:url" content="https://yangfelix.github.io/Llama2Inference.jl/getting_started/"/><meta property="twitter:url" content="https://yangfelix.github.io/Llama2Inference.jl/getting_started/"/><link rel="canonical" href="https://yangfelix.github.io/Llama2Inference.jl/getting_started/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Llama2Inference.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Getting Started</a><ul class="internal"><li><a class="tocitem" href="#Prerequisites"><span>Prerequisites</span></a></li><li><a class="tocitem" href="#Setup"><span>Setup</span></a></li><li><a class="tocitem" href="#Generating-a-random-Story"><span>Generating a random Story</span></a></li><li><a class="tocitem" href="#Generating-a-deterministic-Story"><span>Generating a deterministic Story</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Getting Started</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Getting Started</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/yangfelix/Llama2Inference.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/yangfelix/Llama2Inference.jl/blob/main/docs/src/getting_started.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Getting-Started"><a class="docs-heading-anchor" href="#Getting-Started">Getting Started</a><a id="Getting-Started-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-Started" title="Permalink"></a></h1><p>This page shows some examples on how to use the <code>Llama2Inference</code> module. </p><p>Our first example generates a random story, while the second one uses a random factor, so the output may differ each time you run it.</p><h2 id="Prerequisites"><a class="docs-heading-anchor" href="#Prerequisites">Prerequisites</a><a id="Prerequisites-1"></a><a class="docs-heading-anchor-permalink" href="#Prerequisites" title="Permalink"></a></h2><p>Before running the examples, you need to download the necessary weights. In this example, we use the weights for a small 15M model trained by Andrej Karpathy. Follow these steps:</p><ul><li>Navigate to the directory where you want to download the weights.</li><li>Run the following command:</li></ul><pre><code class="language-bash hljs">wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin</code></pre><ul><li>Additionally, you will need to download the <code>tokenizer.bin</code> file from the GitHub repository.</li></ul><h2 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h2><ul><li>Navigate to the directory where you downloaded the weights.</li></ul><pre><code class="nohighlight hljs">julia
using Pkg
Pkg.activate(&quot;Llama2Inference&quot;)
Pkg.add(url=&quot;https://github.com/yangfelix/Llama2Inference.jl&quot;)
</code></pre><h2 id="Generating-a-random-Story"><a class="docs-heading-anchor" href="#Generating-a-random-Story">Generating a random Story</a><a id="Generating-a-random-Story-1"></a><a class="docs-heading-anchor-permalink" href="#Generating-a-random-Story" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using Llama2Inference</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; config, weights = read_checkpoint(&quot;./stories15M.bin&quot;);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; transformer = Transformer(config, weights);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; tokenizer = build_tokenizer(&quot;./tokenizer.bin&quot;, Int(config.vocab_size));</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; sampler = Sampler(config.vocab_size, 0.5f0, 0.9f0);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; generate(transformer, tokenizer, sampler, 256; prompt=&quot;The universe&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">The universe was big and wide. It was full of stars and planets.
One day, a little girl named Sarah was walking through the universe. She was looking at the stars and planets. Suddenly, she heard a loud noise.
&quot;What was that?&quot; Sarah asked her mom.
&quot;It was just a shooting star,&quot; her mom said. &quot;But it&#39;s not going to hurt you.&quot;
Sarah was scared, so she asked her mom if they could leave.
&quot;No, Sarah,&quot; her mom said. &quot;It&#39;s not safe. You could get hurt.&quot;
Sarah was sad, but she knew her mom was right. She waved goodbye to the universe and went home.
The end.
Generated 158 tokens in 1.0074589252471924 seconds, 157.82281144711425 tokens per second.</code></pre><h2 id="Generating-a-deterministic-Story"><a class="docs-heading-anchor" href="#Generating-a-deterministic-Story">Generating a deterministic Story</a><a id="Generating-a-deterministic-Story-1"></a><a class="docs-heading-anchor-permalink" href="#Generating-a-deterministic-Story" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using Llama2Inference</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; config, weights = read_checkpoint(&quot;./stories15M.bin&quot;);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; transformer = Transformer(config, weights);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; tokenizer = build_tokenizer(&quot;./tokenizer.bin&quot;, Int(config.vocab_size));</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; sampler = Sampler(config.vocab_size, 0.0f0, 0.9f0);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; generate(transformer, tokenizer, sampler, 256; prompt=&quot;The universe&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">The universe was bright and full of stars. Every night, the stars would twinkle and shine. One night, a little girl named Lucy was walking through the universe. She was looking for something special.
Suddenly, she saw a bright light. It was a shooting star! Lucy was so excited. She ran to the shooting star and said, &quot;Hello, star! Can you come down and play with me?&quot;
The shooting star replied, &quot;Yes, I can come down and play with you. But first, you must find me a special star.&quot;
Lucy searched and searched until she found the special star. She said, &quot;I found you! Let&#39;s play together!&quot;
The shooting star smiled and said, &quot;I&#39;m so happy to be here. Let&#39;s play!&quot;
So, Lucy and the shooting star played together all night long. They had so much fun that Lucy was so happy that she forgot to be scared.
The end.
Generated 205 tokens in 1.3978550434112549 seconds, 147.36864238604312 tokens per second.</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The <code>temperature</code> and <code>topp</code> argument of the <a href="../#Llama2Inference.Sampler-Tuple{Int64, Float32, Float32}"><code>Sampler</code></a> control the random factor of the sampled tokens at each timestep and therefore directly control the diversity generated stories with the same setup.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Sunday 30 June 2024 16:29">Sunday 30 June 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
