<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting Started · Llama2Inference.jl</title><meta name="title" content="Getting Started · Llama2Inference.jl"/><meta property="og:title" content="Getting Started · Llama2Inference.jl"/><meta property="twitter:title" content="Getting Started · Llama2Inference.jl"/><meta name="description" content="Documentation for Llama2Inference.jl."/><meta property="og:description" content="Documentation for Llama2Inference.jl."/><meta property="twitter:description" content="Documentation for Llama2Inference.jl."/><meta property="og:url" content="https://yangfelix.github.io/Llama2Inference.jl/getting_started/"/><meta property="twitter:url" content="https://yangfelix.github.io/Llama2Inference.jl/getting_started/"/><link rel="canonical" href="https://yangfelix.github.io/Llama2Inference.jl/getting_started/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Llama2Inference.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Getting Started</a><ul class="internal"><li><a class="tocitem" href="#Setup"><span>Setup</span></a></li><li><a class="tocitem" href="#Generating-a-random-Story"><span>Generating a random Story</span></a></li><li><a class="tocitem" href="#Generating-a-deterministic-Story"><span>Generating a deterministic Story</span></a></li><li><a class="tocitem" href="#Tokenizer-only"><span>Tokenizer only</span></a></li><li><a class="tocitem" href="#Sampler-only"><span>Sampler only</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Getting Started</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Getting Started</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/yangfelix/Llama2Inference.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/yangfelix/Llama2Inference.jl/blob/main/docs/src/getting_started.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Getting-Started"><a class="docs-heading-anchor" href="#Getting-Started">Getting Started</a><a id="Getting-Started-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-Started" title="Permalink"></a></h1><p>This page shows some examples on how to use the <code>Llama2Inference</code> module. </p><p>Our first example generates a deterministic story based on the input (<code>prompt</code>), while the second one uses a random factor, so the output story may differ each time you run it, despite using the same <code>prompt</code>.</p><h2 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h2><p>Open a new Pluto notebook, script or REPL session</p><ul><li>Script or REPL in package mode</li></ul><pre><code class="nohighlight hljs">activate --temp
add https://github.com/yangfelix/Llama2Inference.jl</code></pre><ul><li>Or by creating a new environment in a <a href="https://plutojl.org/">Pluto</a> notebook.</li></ul><pre><code class="nohighlight hljs">begin
    using Pkg
    Pkg.activate(&quot;Llama2Inference&quot;)
    Pkg.add(url=&quot;https://github.com/yangfelix/Llama2Inference.jl&quot;)
end</code></pre><h2 id="Generating-a-random-Story"><a class="docs-heading-anchor" href="#Generating-a-random-Story">Generating a random Story</a><a id="Generating-a-random-Story-1"></a><a class="docs-heading-anchor-permalink" href="#Generating-a-random-Story" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using Llama2Inference</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; config, weights = read_checkpoint(&quot;./bin/stories15M.bin&quot;);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; transformer = Transformer(config, weights);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; tokenizer = build_tokenizer(&quot;./bin/tokenizer.bin&quot;, Int(config.vocab_size));</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; sampler = Sampler(config.vocab_size, 0.5f0, 0.9f0);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; generate(transformer, tokenizer, sampler, 256; prompt=&quot;The universe&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">The universe was filled with bright stars and a sparkling light. Two little friends, Jack and Jill, were playing in the garden.
&quot;Look!&quot; said Jack, pointing to the bright light.
&quot;What is it?&quot; asked Jill.
&quot;It&#39;s a shooting star!&quot; said Jack.
The two friends watched the shooting star for a while, until it suddenly disappeared into the sky.
&quot;Oh no!&quot; said Jack. &quot;Where did it go?&quot;
Jill looked sad.
&quot;I don&#39;t know,&quot; she said. &quot;Let&#39;s go find it.&quot;
So they set off on a journey to find the shooting star. They searched high and low, but they couldn&#39;t find it.
&quot;I&#39;m sorry,&quot; said Jack.
&quot;It&#39;s okay,&quot; said Jill. &quot;We&#39;ll keep looking.&quot;
Finally, after a long time, they found the shooting star. It was hidden in the grass.
&quot;Yay!&quot; shouted Jack. &quot;We found it!&quot;
The two friends hugged each other and smiled.
&quot;Let&#39;s keep looking!&quot; said Jill.
And so they did. They kept looking and looking until they found the shooting star
Generated 255 tokens in 2.069736957550049 seconds, 123.6872149700741 tokens per second.</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>You can download other weights for more complex models pre-trained by Karpathy <a href="https://huggingface.co/karpathy/tinyllamas/tree/main">here</a>. These are not included in this repository to keep the required space lower.</p><p>The above examples work by only changing the path in <code>read_checkpoint(path)</code> to the desired weights file.</p></div></div><h2 id="Generating-a-deterministic-Story"><a class="docs-heading-anchor" href="#Generating-a-deterministic-Story">Generating a deterministic Story</a><a id="Generating-a-deterministic-Story-1"></a><a class="docs-heading-anchor-permalink" href="#Generating-a-deterministic-Story" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using Llama2Inference</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; config, weights = read_checkpoint(&quot;./bin/stories15M.bin&quot;);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; transformer = Transformer(config, weights);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; tokenizer = build_tokenizer(&quot;./bin/tokenizer.bin&quot;, Int(config.vocab_size));</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; sampler = Sampler(config.vocab_size, 0.0f0, 0.9f0);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; generate(transformer, tokenizer, sampler, 256; prompt=&quot;The universe&quot;)</code><code class="nohighlight hljs ansi" style="display:block;">The universe was bright and full of stars. Every night, the stars would twinkle and shine. One night, a little girl named Lucy was walking through the universe. She was looking for something special.
Suddenly, she saw a bright light. It was a shooting star! Lucy was so excited. She ran to the shooting star and said, &quot;Hello, star! Can you come down and play with me?&quot;
The shooting star replied, &quot;Yes, I can come down and play with you. But first, you must find me a special star.&quot;
Lucy searched and searched until she found the special star. She said, &quot;I found you! Let&#39;s play together!&quot;
The shooting star smiled and said, &quot;I&#39;m so happy to be here. Let&#39;s play!&quot;
So, Lucy and the shooting star played together all night long. They had so much fun that Lucy was so happy that she forgot to be scared.
The end.
Generated 205 tokens in 1.4617929458618164 seconds, 140.9228308175686 tokens per second.</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The <code>temperature</code> and <code>topp</code> argument of the <a href="../#Llama2Inference.Sampler-Union{Tuple{Z}, Tuple{T}, Tuple{T, Z, Z}} where {T&lt;:Signed, Z&lt;:AbstractFloat}"><code>Sampler</code></a> control the random factor of the sampled tokens at each timestep and therefore directly control the diversity of the generated stories.</p></div></div><h2 id="Tokenizer-only"><a class="docs-heading-anchor" href="#Tokenizer-only">Tokenizer only</a><a id="Tokenizer-only-1"></a><a class="docs-heading-anchor-permalink" href="#Tokenizer-only" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using Llama2Inference</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; config, _ = read_checkpoint(&quot;./bin/stories15M.bin&quot;);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; tokenizer = build_tokenizer(&quot;./bin/tokenizer.bin&quot;, Int(config.vocab_size));</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; BOS::Bool = true;</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; EOS::Bool = false;</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; prompt1 = &quot;Example prompt&quot;;</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; encoded_prompt = encode(tokenizer, prompt1, BOS, EOS);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; println(&quot;The encoded prompt is: $encoded_prompt&quot;);</code><code class="nohighlight hljs ansi" style="display:block;">The encoded prompt is: [2, 8742, 9509]</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; token = encoded_prompt[1];</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; for next in encoded_prompt[2:end]
           piece = decode(tokenizer, token, next)
           token = next
           safe_print(piece)
       end</code><code class="nohighlight hljs ansi" style="display:block;">Example prompt</code></pre><h2 id="Sampler-only"><a class="docs-heading-anchor" href="#Sampler-only">Sampler only</a><a id="Sampler-only-1"></a><a class="docs-heading-anchor-permalink" href="#Sampler-only" title="Permalink"></a></h2><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; using Llama2Inference</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; temperature = 0.0;</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; topp = 0.0;</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; sampler = Sampler(6, temperature, topp);</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; logits = [0.1f0, 0.3f0, 0.2f0, 0.15f0, 0.15f0, 0.1f0];</code><code class="nohighlight hljs ansi" style="display:block;"></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; index = sample(sampler, logits)</code><code class="nohighlight hljs ansi" style="display:block;">2</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Check the influence of the <code>temperature</code> and <code>topp</code> parameters on the choice of sampling algorithm in the documentation of the <a href="../#Llama2Inference.sample-Tuple{Sampler, Vector{Float32}}"><code>sample</code></a> function.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Tuesday 16 July 2024 13:41">Tuesday 16 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
